{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e869bd7-9e6c-4c70-a214-f649ba59390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import isnull, when, count, col,avg\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import FMRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import min, max, avg\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7914f0a9-c370-42f5-95ef-a5b102eee0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://HP-5CG41667P5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de00bd09-7df8-4988-92d8-6ea7c79d63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.format('csv').option(\"header\",\"True\").option(\"inferSchema\",\"True\").load('50_Startups_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea7bc48-5f9d-45e5-9248-6a3c2744e6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- R&D Spend: double (nullable = true)\n",
      " |-- Administration: double (nullable = true)\n",
      " |-- Marketing Spend: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      "\n",
      "+---+------------------+------------------+------------------+----------+------------------+\n",
      "|_c0|         R&D Spend|    Administration|   Marketing Spend|     State|            Profit|\n",
      "+---+------------------+------------------+------------------+----------+------------------+\n",
      "|  0|165349.30000000002|          136897.9|471784.19999999995|  New York|         192261.93|\n",
      "|  1|162597.80000000002|         151377.69|         443898.63|California|         191792.16|\n",
      "|  2|153441.61000000002|101145.65000000001|407934.63999999996|   Florida|191050.49000000002|\n",
      "|  3|         144372.51|118671.95000000001|         383199.72|  New York|         182902.09|\n",
      "|  4|         142107.44| 91391.87000000001|366168.51999999996|   Florida|         166188.04|\n",
      "+---+------------------+------------------+------------------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"50_Startups_dataset.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee73e5d-ec23-4a05-a2f3-4ff2061660a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+\n",
      "|Min_Profit|Max_Profit|        Avg_Profit|\n",
      "+----------+----------+------------------+\n",
      "|   14681.5| 192261.93|112012.73920000001|\n",
      "+----------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Minimum, Max and Avf Profit from dataset\n",
    "\n",
    "df.select(\n",
    "    min(\"Profit\").alias(\"Min_Profit\"),\n",
    "    max(\"Profit\").alias(\"Max_Profit\"),\n",
    "    avg(\"Profit\").alias(\"Avg_Profit\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b0595e5-18d0-4ace-9bdf-6948839e78d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|     State|count|\n",
      "+----------+-----+\n",
      "|California|   17|\n",
      "+----------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Most startup\n",
    "\n",
    "df.groupby(\"State\").count().orderBy('count', ascending=[False]).show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "548bbe86-dbbb-45e9-a64f-1fc818bdb24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|     State|count|\n",
      "+----------+-----+\n",
      "|California|   17|\n",
      "+----------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df.groupBy(\"State\") \\\n",
    "  .count() \\\n",
    "  .orderBy(desc(\"count\")) \\\n",
    "  .show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc186304-ced0-48cc-b9bc-13fd158bf4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(iii) Average Administration cost for startups in Florida\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df.filter(df.State == \"Florida\") \\\n",
    "  .agg(avg(\"Administration\").alias(\"Avg_Admin_Florida\")) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ad4a83b-e9c4-4aca-865e-cf551bdcba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       Avg_Florida|\n",
      "+------------------+\n",
      "|121768.99750000004|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.State==\"Florida\").agg(avg(\"Administration\").alias(\"Avg_Florida\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfdd99ea-a03d-4325-b67d-b55997675932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|  Avg_Florida_Cost|\n",
      "+------------------+\n",
      "|121768.99750000004|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.State==\"Florida\").select(avg(\"Administration\").alias(\"Avg_Florida_Cost\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edeaf120-1505-49ef-9c58-9d3c39b3aabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(iv) How many startups are located in California?\n",
    "\n",
    "df.filter(df.State==\"California\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18a054e3-e3a3-43b7-ad25-b00f76b89486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Out of startups with Profit > 100000, how many spent < 50000 on Marketing?\n",
    "df.filter((df.Profit>100000) & (df[\"Marketing Spend\"]<50000)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "202a7c18-e125-419f-8924-5fe33c6d813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\n",
    "    (df.Profit > 100000) &\n",
    "    (df[\"Marketing Spend\"] < 50000)\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e06aded-2049-4d36-a68b-c51d8c8cd400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, R&D Spend: double, Administration: double, Marketing Spend: double, State: string, Profit: double]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(vi) Remove feature sl no and drop rows with any null values\n",
    "\n",
    "df.drop(\"sl no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8b603f4-127c-498f-b3c9-f0bd96bf0ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- R&D Spend: double (nullable = true)\n",
      " |-- Administration: double (nullable = true)\n",
      " |-- Marketing Spend: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc129a2b-81b2-4402-9df5-af2da0f0ebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[_c0: int, R&D Spend: double, Administration: double, Marketing Spend: double, State: string, Profit: double]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23e324da-46b8-4caf-9b24-6e4c539421c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------------------+------------------+----------+------------------+\n",
      "|_c0|         R&D Spend|    Administration|   Marketing Spend|     State|            Profit|\n",
      "+---+------------------+------------------+------------------+----------+------------------+\n",
      "|  0|165349.30000000002|          136897.9|471784.19999999995|  New York|         192261.93|\n",
      "|  1|162597.80000000002|         151377.69|         443898.63|California|         191792.16|\n",
      "|  2|153441.61000000002|101145.65000000001|407934.63999999996|   Florida|191050.49000000002|\n",
      "|  3|         144372.51|118671.95000000001|         383199.72|  New York|         182902.09|\n",
      "|  4|         142107.44| 91391.87000000001|366168.51999999996|   Florida|         166188.04|\n",
      "+---+------------------+------------------+------------------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1872a5c0-484f-4443-8625-ed186df39115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0efba0ba-b521-4840-8236-cb0f9e2ce5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08b5c94b-4a6a-4019-868b-17082fbb001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------------------+------------------+----------+------------------+\n",
      "|_c0|         R&D Spend|    Administration|   Marketing Spend|     State|            Profit|\n",
      "+---+------------------+------------------+------------------+----------+------------------+\n",
      "|  0|165349.30000000002|          136897.9|471784.19999999995|  New York|         192261.93|\n",
      "|  1|162597.80000000002|         151377.69|         443898.63|California|         191792.16|\n",
      "|  2|153441.61000000002|101145.65000000001|407934.63999999996|   Florida|191050.49000000002|\n",
      "|  3|         144372.51|118671.95000000001|         383199.72|  New York|         182902.09|\n",
      "|  4|         142107.44| 91391.87000000001|366168.51999999996|   Florida|         166188.04|\n",
      "+---+------------------+------------------+------------------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "644d105b-9896-4759-9cc0-3b31bc9c0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"_c0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a80a3e0b-bd84-4d40-b9b3-79ba8ced6d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+----------+------------------+\n",
      "|         R&D Spend|    Administration|   Marketing Spend|     State|            Profit|\n",
      "+------------------+------------------+------------------+----------+------------------+\n",
      "|165349.30000000002|          136897.9|471784.19999999995|  New York|         192261.93|\n",
      "|162597.80000000002|         151377.69|         443898.63|California|         191792.16|\n",
      "|153441.61000000002|101145.65000000001|407934.63999999996|   Florida|191050.49000000002|\n",
      "|         144372.51|118671.95000000001|         383199.72|  New York|         182902.09|\n",
      "|         142107.44| 91391.87000000001|366168.51999999996|   Florida|         166188.04|\n",
      "+------------------+------------------+------------------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcd0f330-7de4-433e-a56a-86bc9aed2853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------+------------------------+--------------+---------------+\n",
      "|R&D Spend_non_null|Administration_non_null|Marketing Spend_non_null|State_non_null|Profit_non_null|\n",
      "+------------------+-----------------------+------------------------+--------------+---------------+\n",
      "|                50|                     50|                      50|            50|             50|\n",
      "+------------------+-----------------------+------------------------+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Number of record in each column\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "df.select([\n",
    "    count(col(c)).alias(c + \"_non_null\")\n",
    "    for c in df.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ae9dacb-e2a7-4144-a333-5f98b84b536f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+---------------------+-----------+------------+\n",
      "|R&D Spend_nulls|Administration_nulls|Marketing Spend_nulls|State_nulls|Profit_nulls|\n",
      "+---------------+--------------------+---------------------+-----------+------------+\n",
      "|              0|                   0|                    0|          0|           0|\n",
      "+---------------+--------------------+---------------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count null\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "df.select([\n",
    "    sum(col(c).isNull().cast(\"int\")).alias(c + \"_nulls\")\n",
    "    for c in df.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4317f735-79ec-4726-af09-735c0e9e6bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataframe: 50\n"
     ]
    }
   ],
   "source": [
    "total = df.count()\n",
    "print(\"Total rows in dataframe:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efef72a3-0fb2-403f-bd0c-ed4003f94ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------+------------------------+--------------+---------------+\n",
      "|R&D Spend_non_null|Administration_non_null|Marketing Spend_non_null|State_non_null|Profit_non_null|\n",
      "+------------------+-----------------------+------------------------+--------------+---------------+\n",
      "|                50|                     50|                      50|            50|             50|\n",
      "+------------------+-----------------------+------------------------+--------------+---------------+\n",
      "\n",
      "+---------------+--------------------+---------------------+-----------+------------+\n",
      "|R&D Spend_nulls|Administration_nulls|Marketing Spend_nulls|State_nulls|Profit_nulls|\n",
      "+---------------+--------------------+---------------------+-----------+------------+\n",
      "|              0|                   0|                    0|          0|           0|\n",
      "+---------------+--------------------+---------------------+-----------+------------+\n",
      "\n",
      "Total rows: 50\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum, count\n",
    "\n",
    "total = df.count()\n",
    "\n",
    "summary = df.select([\n",
    "    count(col(c)).alias(c + \"_non_null\")\n",
    "    for c in df.columns\n",
    "])\n",
    "\n",
    "summary_nulls = df.select([\n",
    "    sum(col(c).isNull().cast(\"int\")).alias(c + \"_nulls\")\n",
    "    for c in df.columns\n",
    "])\n",
    "\n",
    "summary.show()\n",
    "summary_nulls.show()\n",
    "\n",
    "print(\"Total rows:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e314c687-9994-4ae0-a49c-8abe976062cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(i) Use StringIndexer to convert all string columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d389e473-55bf-4d80-bc17-5d8e9b1996f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+----------+------------------+-----------+\n",
      "|         R&D Spend|    Administration|   Marketing Spend|     State|            Profit|State_index|\n",
      "+------------------+------------------+------------------+----------+------------------+-----------+\n",
      "|165349.30000000002|          136897.9|471784.19999999995|  New York|         192261.93|        1.0|\n",
      "|162597.80000000002|         151377.69|         443898.63|California|         191792.16|        0.0|\n",
      "|153441.61000000002|101145.65000000001|407934.63999999996|   Florida|191050.49000000002|        2.0|\n",
      "|         144372.51|118671.95000000001|         383199.72|  New York|         182902.09|        1.0|\n",
      "|         142107.44| 91391.87000000001|366168.51999999996|   Florida|         166188.04|        2.0|\n",
      "+------------------+------------------+------------------+----------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- R&D Spend: double (nullable = true)\n",
      " |-- Administration: double (nullable = true)\n",
      " |-- Marketing Spend: double (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      " |-- State_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# find all string-type columns\n",
    "string_cols = [c for c, t in df.dtypes if t == \"string\"]\n",
    "\n",
    "for col_name in string_cols:\n",
    "    indexer = StringIndexer(inputCol=col_name, outputCol=col_name + \"_index\")\n",
    "    df = indexer.fit(df).transform(df)\n",
    "\n",
    "df.show(5)\n",
    "\n",
    "# drop original string columns (keep only numeric + indexed)\n",
    "df = df.drop(*string_cols)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14e0a6f3-c56a-4043-9f66-e9fe58146693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|            Profit|\n",
      "+--------------------+------------------+\n",
      "|[165349.300000000...|         192261.93|\n",
      "|[162597.800000000...|         191792.16|\n",
      "|[153441.610000000...|191050.49000000002|\n",
      "|[144372.51,118671...|         182902.09|\n",
      "|[142107.44,91391....|         166188.04|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(ii) Use VectorAssembler to create a features column; keep only features and Profit\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_cols = [c for c in df.columns if c != \"Profit\"]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "final_df = assembler.transform(df).select(\"features\", \"Profit\")\n",
    "final_df.show(5)\n",
    "final_df.printSchema()   # should show 'features' (vector) and 'Profit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7885107e-be82-4d51-858f-065d69da9c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rows: 33\n",
      "Testing rows: 17\n"
     ]
    }
   ],
   "source": [
    "#(iii) Split the data into training and test sets (3:1 ratio)\n",
    "train_df, test_df = final_df.randomSplit([0.75, 0.25], seed=42)\n",
    "\n",
    "print(\"Training rows:\", train_df.count())\n",
    "print(\"Testing rows:\", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27a87b03-51f7-4bff-9fb6-4440984e9585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.8045625059339423,-0.02265390732952868,0.017240446450070918,195.21886126982628]\n",
      "Intercept: 50937.839497552806\n"
     ]
    }
   ],
   "source": [
    "#(iv) Build a LinearRegression model with default parameters\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Profit\")\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "print(\"Coefficients:\", lr_model.coefficients)\n",
    "print(\"Intercept:\", lr_model.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9366086-d414-4b90-9ca6-befcee88b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-----------------+\n",
      "|            features|           Profit|       prediction|\n",
      "+--------------------+-----------------+-----------------+\n",
      "|[542.15,51743.25,...|         35673.51|50397.06685503073|\n",
      "|[20229.69,65948.0...|         81229.16|69109.18263896614|\n",
      "|[23641.03,96189.7...|71498.59000000001|70331.05954329063|\n",
      "|[27893.0199999999...|77798.93000000001|74686.47328297907|\n",
      "|[44070.0499999999...|         89949.24|88630.06048431213|\n",
      "+--------------------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Mean Squared Error (MSE) = 60950469.93518621\n"
     ]
    }
   ],
   "source": [
    "#(v) Predict on the test data and calculate MSE\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"features\", \"Profit\", \"prediction\").show(5)\n",
    "\n",
    "evaluator_mse = RegressionEvaluator(\n",
    "    labelCol=\"Profit\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mse\"\n",
    ")\n",
    "\n",
    "mse = evaluator_mse.evaluate(predictions)\n",
    "print(\"Mean Squared Error (MSE) =\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2003096b-7750-42f8-b26c-3a19188cfd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) = 7807.078194509531\n"
     ]
    }
   ],
   "source": [
    "#(vi) Calculate RMSE on the test data\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"Profit\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) =\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9598f-a5ff-4288-a5aa-73e074ed977e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
